Blender exporter - storing camera, point light, sphere, cube and plane details in a JSON file

Camera space transforms - C++ camera class with methods to: read the exported JSON file and store camera information, method to convert pixel coordinates to a ray (with Ray class) in world coordinates

Image read and write - C++ image class with a constructor that takes a file name, methods to read and modify pixel  values of the image and a method that writes the image to a chosen file

Ray intersection - implemented ray intersection checker for each shape type, ensuring to transform the ray according to the shape's transformation and editing a hit structure object to include the intersection point and its distance along the ray.

Acceleration - implemented a bounding volume hierarchy structure using axis-aligned bounded boxes for each shape to speed up the ray-tracing processes

Whitted-style Raytracing - for each pixel in the camera's image plane, a ray is traced into the scene. The ray's intersection with scene shapes is tested, then shaded appropriately via Blinn-Phong. Refracted and reflected rays are traced recursively, with their contributions adding to the final pixel colour.

Anti-alisaing - for each pixel, a chosen number of random samples (via Monte Carlo sampling) are taken from within the pixel and averaged to calculate the pixel colour

Textures - Hit point (u, v) on the intersected shape's texture is calculated and then sampled from to give the base/diffuse colour of the intersected point (x, y)

System integration - separated main raytracer into smaller modules to increase modularity, and turned regularly used processes into helper functions to decrease code repetition. Command line arguments were added to turn on/off features e.g. anti-aliasing, texture mapping, depth of field, reflections, glossy reflections, soft shadows and motion blur.

Distributed raytracing effects - included soft shadows and glossy reflection using Monte Carlo distributed raytracing

Lens effects - implemented depth of field using Blender camera focal distance and aperture, and motion blur by interpolating object position between timestamps 0 and 1, giving each ray a time and averaging to get blurry colour across motion 
